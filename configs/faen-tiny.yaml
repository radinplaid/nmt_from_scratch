model:
  d_model: 256
  enc_layers: 6
  dec_layers: 2
  n_heads: 8
  ffn_dim: 1024
  max_len: 256
  vocab_size: 20000
train:
  experiment_name: "faen-tiny"
  src_lang: "fa"
  tgt_lang: "en"
  src_train_path: "data/train.fa"
  tgt_train_path: "data/train.en"
  src_dev_path: "data/dev.fa"
  tgt_dev_path: "data/dev.en"
  aim_repo: "~/mt/.aim"
  max_tokens_per_batch: 20000
  buffer_size: 150000
  num_workers: 4
  lr: 5.0e-4
  accum_steps: 2
  warmup_steps: 5000
  max_steps: 100000
  eval_steps: 2500
  max_checkpoints: 4
export:
  k: 4
  output_prefix: "faen-tiny/averaged_model"
  export_int8: true
  calib_batches: 200
  model_path: "faen-tiny/averaged_model_int8.pt"
  output_dir: "faen-tiny/ct2_model"
  quantization: "int8"